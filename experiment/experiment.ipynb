{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09ed2de3",
   "metadata": {},
   "source": [
    "Project Structure\n",
    "- Setup Chunking and processing steps for inputs (PDFs, docx, txt)\n",
    "- Setup PGVector Store (VS) + postgresql => Done\n",
    "- Using LLMs (OpenAI, Gemini,...) to query vectors from VS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d89cd4e",
   "metadata": {},
   "source": [
    "# Create PostgreDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "356d472c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('/Users/longnguyen/Documents/coding/fastapi/rag_with_llama/deployment/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2fc01b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "db_name = os.environ['POSTGRES_DB']\n",
    "host = \"localhost\"\n",
    "password = os.environ['POSTGRES_PASSWORD']\n",
    "port = \"5432\"\n",
    "user = os.environ['POSTGRES_USER']\n",
    "# conn = psycopg2.connect(connection_string)\n",
    "conn = psycopg2.connect(\n",
    "    dbname=db_name,\n",
    "    host=host,\n",
    "    password=password,\n",
    "    port=port,\n",
    "    user=user,\n",
    ")\n",
    "conn.autocommit = True\n",
    "\n",
    "# with conn.cursor() as c:\n",
    "#     c.execute(f\"DROP DATABASE IF EXISTS {db_name}\")\n",
    "#     c.execute(f\"CREATE DATABASE {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c0431d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'user': 'admin', 'channel_binding': 'prefer', 'dbname': 'rag_db', 'host': 'localhost', 'port': '5432', 'options': '', 'sslmode': 'prefer', 'sslcompression': '0', 'sslcertmode': 'allow', 'sslsni': '1', 'ssl_min_protocol_version': 'TLSv1.2', 'gssencmode': 'prefer', 'krbsrvname': 'postgres', 'gssdelegation': '0', 'target_session_attrs': 'any', 'load_balance_hosts': 'disable'}\n",
      "Connection is active\n"
     ]
    }
   ],
   "source": [
    "print(conn.status)\n",
    "print(conn.get_dsn_parameters())\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(\"SELECT 1\")\n",
    "    print(\"Connection is active\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeb5fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6fbefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f75f42d",
   "metadata": {},
   "source": [
    "# Checking file input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08ca7925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, field_validator\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from uuid import UUID\n",
    "from chonkie import TokenChunker, SemanticChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1770fbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/project/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from pathlib import Path\n",
    "import PyPDF2\n",
    "from chonkie import SemanticChunker\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract text from PDF file using PyPDF2.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted text from all pages\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def chunk_with_semantic_chunker(text, chunk_size=512, similarity_threshold=0.7, embedding_model=None):\n",
    "    \"\"\"\n",
    "    Chunk text using Chonkie's SemanticChunker with custom embedding model.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text to chunk\n",
    "        chunk_size (int): Maximum tokens per chunk\n",
    "        similarity_threshold (float): Similarity threshold for semantic chunking\n",
    "        embedding_model: Custom embedding model (SentenceTransformer or similar)\n",
    "\n",
    "    Returns:\n",
    "        list: List of chunks\n",
    "    \"\"\"\n",
    "    if embedding_model:\n",
    "        chunker = SemanticChunker(\n",
    "            chunk_size=chunk_size,\n",
    "            similarity_threshold=similarity_threshold,\n",
    "            embedding_model=embedding_model\n",
    "        )\n",
    "    else:\n",
    "        # Use default embedding model\n",
    "        chunker = SemanticChunker(\n",
    "            chunk_size=chunk_size,\n",
    "            similarity_threshold=similarity_threshold\n",
    "        )\n",
    "\n",
    "    chunks = chunker.chunk(text)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def save_chunks_to_file(chunks, output_path, chunker_type):\n",
    "    \"\"\"\n",
    "    Save chunks to a text file.\n",
    "\n",
    "    Args:\n",
    "        chunks (list): List of chunks\n",
    "        output_path (str): Output file path\n",
    "        chunker_type (str): Type of chunker used\n",
    "    \"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"Chunks created using {chunker_type}\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "        for i, chunk in enumerate(chunks, 1):\n",
    "            f.write(f\"Chunk {i}:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            f.write(f\"{chunk.text}\\n\\n\")\n",
    "            f.write(f\"Tokens: {chunk.token_count}\\n\")\n",
    "            if hasattr(chunk, 'start_index'):\n",
    "                f.write(f\"Start Index: {chunk.start_index}\\n\")\n",
    "            if hasattr(chunk, 'end_index'):\n",
    "                f.write(f\"End Index: {chunk.end_index}\\n\")\n",
    "            f.write(\"\\n\" + \"=\"*50 + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aedf171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1: Loading documents\n",
      "\n",
      "Step 2: Chunking with SemanticChunker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/project/lib/python3.12/site-packages/chonkie/embeddings/auto.py:87: UserWarning: Failed to load minishlab/potion-base-32M with Model2VecEmbeddings: model2vec is not available. Please install it via `pip install chonkie[model2vec]`\n",
      "Falling back to loading default provider model.\n",
      "  warnings.warn(\n",
      "/usr/local/Caskroom/miniconda/base/envs/project/lib/python3.12/site-packages/chonkie/embeddings/auto.py:95: UserWarning: Failed to load the default model for Model2VecEmbeddings: model2vec is not available. Please install it via `pip install chonkie[model2vec]`\n",
      "Falling back to SentenceTransformerEmbeddings.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 1: Loading documents\")\n",
    "# texts = extract_text_from_pdf(r'D:\\Project\\rag_with_llama\\docs\\llama2.pdf')\n",
    "texts = extract_text_from_pdf(r'../docs/llama2.pdf')\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"chunked_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"\\nStep 2: Chunking with SemanticChunker\")\n",
    "semantic_chunks = chunk_with_semantic_chunker(\n",
    "    texts,\n",
    "    chunk_size=512,\n",
    "    similarity_threshold=0.7\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eb4060f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chunk(text='Llama 2 : Open Foundation and Fine-Tuned Chat Models\n",
       "Hugo Touvron∗Louis Martin†Kevin Stone†\n",
       "Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\n",
       "', token_count=43, start_index=0, end_index=167)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5448515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "class EmbeddingGenerator:\n",
    "    \"\"\"Generate embeddings using SentenceTransformers.\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initialize embedding generator.\n",
    "\n",
    "        Args:\n",
    "            model_name: SentenceTransformer model name\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.embedding_dim = self.model.get_sentence_embedding_dimension()\n",
    "\n",
    "    def embed_text(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        Generate embedding for a single text.\n",
    "        Args:\n",
    "            text: Input text\n",
    "        Returns:\n",
    "            List of embedding values\n",
    "        \"\"\"\n",
    "        embedding = self.model.encode(text)\n",
    "        return embedding.tolist()\n",
    "\n",
    "    def embed_batch(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Generate embeddings for multiple texts.\n",
    "        Args:\n",
    "            texts: List of input texts\n",
    "        Returns:\n",
    "            List of embedding lists\n",
    "        \"\"\"\n",
    "        embeddings = self.model.encode(texts)\n",
    "        return [emb.tolist() for emb in embeddings]\n",
    "\n",
    "embedding_model = './embedded_model/all-MiniLM-L6-v2'\n",
    "embedding_generator = EmbeddingGenerator(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "132653c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_txt = embedding_generator.embed_batch(semantic_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33e004a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1332"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e38b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector  # Missing import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dde964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- First, turn off the pager to avoid the 'more' error\n",
    "# \\pset pager off\n",
    "\n",
    "# -- Now run your queries (notice the semicolon at the end)\n",
    "# SELECT version();\n",
    "\n",
    "# SELECT 2+2 AS result;\n",
    "\n",
    "# SELECT NOW();\n",
    "\n",
    "# SELECT 'Hello PostgreSQL!' AS message;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f89015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sentence_transformers\n",
    "# model = sentence_transformers.SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# model.save('./embedded_model/all-MiniLM-L6-v2')\n",
    "# model_test = sentence_transformers.SentenceTransformer('./embedded_model/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb580acd",
   "metadata": {},
   "source": [
    "# Test fulll flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fa63fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ddc6f726",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/longnv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from fastapi import FastAPI, File, UploadFile, HTTPException, Form\n",
    "from fastapi.responses import HTMLResponse\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import sys\n",
    "sys.path.append('../document_processing')  # Go up one level, then into folder\n",
    "\n",
    "import sys\n",
    "sys.path.append('../docs')  # Go up one level, then into folder\n",
    "\n",
    "# Your existing components - unchanged\n",
    "from embed_chunks_to_db import ChunkEmbeddingPipeline, EmbeddingGenerator, VectorStore\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8266c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_params = {\n",
    "    'host': os.getenv('DB_HOST', 'localhost'),\n",
    "    'port': os.getenv('DB_PORT', '5432'),\n",
    "    'dbname': os.getenv('DB_NAME', 'rag_db'),\n",
    "    'user': os.getenv('DB_USER', 'admin'),\n",
    "    'password': os.getenv('DB_PASSWORD', 'admin')\n",
    "}\n",
    "\n",
    "table_name = 'document_chunks'\n",
    "\n",
    "# Don't initialize models at startup\n",
    "pipeline = None\n",
    "def get_pipeline():\n",
    "    global pipeline\n",
    "    if pipeline is None:\n",
    "        pipeline = ChunkEmbeddingPipeline(\n",
    "                    db_params=db_params,\n",
    "                    embedding_model='all-MiniLM-L6-v2',\n",
    "                    table_name=table_name\n",
    "                )\n",
    "    return pipeline\n",
    "\n",
    "pipeline = get_pipeline()\n",
    "file = pipeline.extract_text_from_pdf(r'../docs/llama2.pdf')\n",
    "chunks = pipeline.chunk_text(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62b751d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Vector type working: [1. 2. 3.]\n",
      "✓ Cosine distance: 1.000\n",
      "✓ Embedding column: ('embedding', 'USER-DEFINED')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_pgvector_connection():\n",
    "    \"\"\"Validate pgvector integration at the connection level\"\"\"\n",
    "    vector_store = VectorStore(db_params, 'document_chunks')\n",
    "    \n",
    "    try:\n",
    "        conn = vector_store._get_connection()\n",
    "        with conn.cursor() as cur:\n",
    "            # Test 1: Confirm pgvector types are registered\n",
    "            cur.execute(\"SELECT '[1,2,3]'::vector;\")\n",
    "            result = cur.fetchone()[0]\n",
    "            print(f\"✓ Vector type working: {result}\")\n",
    "            \n",
    "            # Test 2: Verify cosine distance operator\n",
    "            cur.execute(\"SELECT '[1,0,0]'::vector <=> '[0,1,0]'::vector;\")\n",
    "            distance = cur.fetchone()[0]\n",
    "            print(f\"✓ Cosine distance: {distance:.3f}\")\n",
    "            \n",
    "            # Test 3: Table schema validation\n",
    "            cur.execute(f\"\"\"\n",
    "                SELECT column_name, data_type \n",
    "                FROM information_schema.columns \n",
    "                WHERE table_name = '{vector_store.table_name}' \n",
    "                AND column_name = 'embedding'\n",
    "            \"\"\")\n",
    "            schema = cur.fetchone()\n",
    "            print(f\"✓ Embedding column: {schema}\")\n",
    "            \n",
    "        conn.close()\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ pgvector connection failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "test_pgvector_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8291d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Chunk:\n",
    "    \"\"\"Chunk data structure to match your existing interface.\"\"\"\n",
    "    id: str\n",
    "    document_id: str\n",
    "    text: str\n",
    "    embedding: List[float]\n",
    "    metadata: Optional[Dict] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "232fc845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings in batch\n",
    "print(\"Generating embeddings...\")\n",
    "embeddings = pipeline.embedding_generator.embed_batch([chunk.text for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ac37546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 512\n",
    "similarity_threshold = 0.7\n",
    "filename = 'llama2.pdf'\n",
    "file_type = 'pdf'\n",
    "file_size = len(file)\n",
    "document_id = str(uuid.uuid4())\n",
    "metadata = {'source': 'llama2.pdf'}\n",
    "\n",
    "# Create Chunk objects using your interface\n",
    "chunk_objects = []\n",
    "for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n",
    "    chunk_metadata = {\n",
    "        'chunk_index': i,\n",
    "        'token_count': chunk.token_count,\n",
    "        'start_index': getattr(chunk, 'start_index', None),\n",
    "        'end_index': getattr(chunk, 'end_index', None),\n",
    "        'chunk_size': chunk_size,\n",
    "        'similarity_threshold': similarity_threshold,\n",
    "        'embedding_model': pipeline.embedding_generator.model_name,\n",
    "        'embedding_dimension': len(embedding),\n",
    "        'filename': filename,\n",
    "        'file_type': file_type,\n",
    "        'file_size': file_size\n",
    "    }\n",
    "\n",
    "    # Add any additional metadata\n",
    "    if metadata:\n",
    "        chunk_metadata.update(metadata)\n",
    "\n",
    "    chunk_obj = Chunk(\n",
    "        id=str(uuid.uuid4()),\n",
    "        document_id=document_id,\n",
    "        text=chunk.text,\n",
    "        embedding=embedding,\n",
    "        metadata=chunk_metadata\n",
    "    )\n",
    "    chunk_objects.append(chunk_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31b78593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting chunks into database using pgvector...\n"
     ]
    }
   ],
   "source": [
    "# Use your add_chunks method with pgvector\n",
    "print(\"Inserting chunks into database using pgvector...\")\n",
    "pipeline.vector_store.add_chunks(chunk_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee851e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Search operational: 1 results\n"
     ]
    }
   ],
   "source": [
    "test_results = pipeline.search_documents('text', limit=1, threshold=0.1)\n",
    "assert len(test_results) > 0, \"Insert succeeded but search failed\"\n",
    "print(f\"✓ Search operational: {len(test_results)} results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdb0aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data truncated instantly\n",
      "✓ Table schema dropped\n"
     ]
    }
   ],
   "source": [
    "# def fast_reset_vector_store(vector_store):\n",
    "#     \"\"\"Two-step reset: TRUNCATE then DROP for optimal performance\"\"\"\n",
    "#     conn = vector_store._get_connection()\n",
    "    \n",
    "#     try:\n",
    "#         with conn.cursor() as cur:\n",
    "#             # Step 1: Instant data removal (no WAL overhead)\n",
    "#             cur.execute(f\"TRUNCATE TABLE {vector_store.table_name} CASCADE;\")\n",
    "#             print(\"✓ Data truncated instantly\")\n",
    "            \n",
    "#             # Step 2: Clean schema removal\n",
    "#             cur.execute(f\"DROP TABLE {vector_store.table_name} CASCADE;\")\n",
    "#             print(\"✓ Table schema dropped\")\n",
    "            \n",
    "#         conn.commit()\n",
    "        \n",
    "#     except Exception as e:\n",
    "#         conn.rollback()\n",
    "#         raise e\n",
    "#     finally:\n",
    "#         conn.close()\n",
    "\n",
    "# # Usage\n",
    "# fast_reset_vector_store(pipeline.vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9569d22d",
   "metadata": {},
   "source": [
    "# Check inserting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b8653e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify success\n",
    "conn = pipeline.vector_store._get_connection()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(f\"SELECT COUNT(*) FROM {pipeline.vector_store.table_name}\")\n",
    "    count_after = cur.fetchone()[0]\n",
    "    \n",
    "    # Validate embedding integrity\n",
    "    cur.execute(f\"\"\"\n",
    "        SELECT *\n",
    "        FROM {pipeline.vector_store.table_name} \n",
    "        ORDER BY created_at DESC LIMIT 2\n",
    "    \"\"\")\n",
    "    \n",
    "    results = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b800dad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0cef73c0-a5ea-4b45-93f7-152110c773a0',\n",
       " '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       " 'Prajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\n',\n",
       " array([ 7.12140650e-03,  1.58904716e-01, -4.11183424e-02, -1.60896499e-02,\n",
       "        -1.19244307e-01,  1.66793726e-02,  7.66922235e-02,  2.09896639e-03,\n",
       "        -7.99249765e-03, -3.11004985e-02,  6.69134455e-03, -1.19025603e-01,\n",
       "         9.55456793e-02, -4.00688797e-02,  2.43884884e-03,  2.39558239e-02,\n",
       "        -2.64738058e-03,  2.02801265e-02,  7.83016905e-03, -7.15690851e-02,\n",
       "        -2.38060020e-02, -1.06638998e-01, -9.48443916e-03,  2.73222420e-02,\n",
       "        -6.30895793e-02, -4.59778449e-03,  1.97286680e-02,  1.22988073e-03,\n",
       "         2.02850271e-02, -3.98318060e-02, -3.29108462e-02,  1.30037352e-01,\n",
       "         7.59432688e-02, -2.78772581e-02, -1.24753239e-02,  8.16547722e-02,\n",
       "        -5.94117120e-02,  4.51860111e-03,  1.69892292e-02, -4.73478902e-03,\n",
       "        -2.29553226e-02,  7.49923289e-03, -2.45867502e-02, -6.85824007e-02,\n",
       "         4.61076982e-02, -7.90486857e-03,  3.45357135e-02,  4.29701656e-02,\n",
       "        -1.81527287e-02,  3.94386984e-03, -1.12031281e-01, -1.33849233e-02,\n",
       "         2.95562968e-02, -5.68636507e-02, -1.91135257e-02, -4.89593633e-02,\n",
       "        -2.09067129e-02,  2.54858583e-02,  2.22643632e-02, -7.60168508e-02,\n",
       "         6.34239987e-02,  4.02081087e-02, -7.23926499e-02, -2.93469126e-03,\n",
       "        -6.95489207e-03, -1.99586619e-02, -5.47327213e-02, -6.26659393e-02,\n",
       "        -5.50053380e-02, -3.49979922e-02,  5.01937158e-02, -4.63738479e-02,\n",
       "        -5.19338474e-02, -2.70534437e-02, -4.35601696e-02, -4.47141044e-02,\n",
       "         1.51812294e-02, -2.63850186e-02, -5.31597435e-02, -5.92830963e-02,\n",
       "        -8.20158124e-02, -3.04792225e-02,  2.42744926e-02,  5.42199053e-02,\n",
       "        -2.90954467e-02,  4.95423526e-02, -7.87444320e-03, -3.05384248e-02,\n",
       "        -2.47603059e-02, -3.60754542e-02,  9.20121837e-03,  4.02520634e-02,\n",
       "        -2.28688978e-02,  4.39353213e-02, -7.07207397e-02,  3.69134136e-02,\n",
       "         2.79467343e-03,  2.21682582e-02,  1.65243316e-02,  9.99063402e-02,\n",
       "         2.19089799e-02,  2.90145334e-02,  6.05171099e-02,  1.35710761e-02,\n",
       "        -1.58481196e-01, -4.70414683e-02,  4.13059294e-02,  6.38688728e-02,\n",
       "         1.91920176e-02,  1.73744671e-02, -3.81577015e-02,  7.30553409e-03,\n",
       "        -3.25665027e-02, -1.01912543e-01, -4.59164493e-02, -1.08445007e-02,\n",
       "        -2.01329105e-02,  4.14437801e-02, -3.18212733e-02,  2.55878437e-02,\n",
       "         3.90040651e-02,  5.42499535e-02, -6.37429953e-02, -6.79228976e-02,\n",
       "         1.62571687e-02, -2.59845518e-02,  5.26357926e-02,  1.99033851e-32,\n",
       "        -4.95871827e-02, -7.90225193e-02,  9.21913460e-02,  3.56467366e-02,\n",
       "         4.26651491e-03, -5.04414849e-02,  5.72552858e-03, -8.60541537e-02,\n",
       "        -2.67258249e-02, -3.08261216e-02,  4.47884426e-02, -3.62987556e-02,\n",
       "         1.18823377e-02, -5.44895008e-02,  1.08716570e-01,  4.03876938e-02,\n",
       "        -2.28537563e-02, -9.44421589e-02, -1.51066873e-02, -4.98357869e-04,\n",
       "         3.80847156e-02,  5.21642007e-02,  4.60770875e-02,  1.45992888e-02,\n",
       "         3.70202474e-02,  5.84117696e-02,  1.20251216e-01, -1.98231377e-02,\n",
       "         6.56113401e-03,  5.06151505e-02,  8.78756344e-02, -2.27499567e-02,\n",
       "        -8.11563209e-02, -4.98249568e-02, -2.63267681e-02, -2.03689863e-03,\n",
       "        -5.87149225e-02, -1.28698833e-02, -5.34305014e-02, -4.73356843e-02,\n",
       "         2.73009297e-02, -7.30978101e-02,  2.87801493e-02, -3.14410143e-02,\n",
       "         2.24582478e-02,  4.58435714e-02,  7.48047084e-02,  6.37950152e-02,\n",
       "         1.31521095e-03,  2.74903048e-02, -2.85092257e-02,  4.53276187e-02,\n",
       "         5.38056670e-03,  4.09435779e-02,  1.66451894e-02, -6.75904378e-02,\n",
       "         2.06154920e-02,  2.42883749e-02, -7.47049153e-02,  8.88601616e-02,\n",
       "         2.31793839e-02,  7.47747570e-02, -3.27695273e-02,  9.43940952e-02,\n",
       "        -3.37526500e-02, -5.39264716e-02,  6.41731312e-03, -6.64855465e-02,\n",
       "         4.43784818e-02, -6.38131946e-02, -4.49763089e-02, -2.10196301e-02,\n",
       "         3.02143265e-02,  7.05433413e-02, -8.37858170e-02, -3.68047156e-04,\n",
       "        -6.19669259e-02, -5.90805225e-02, -7.67595470e-02,  4.91671637e-02,\n",
       "        -5.38995415e-02,  1.21844327e-02,  2.39255894e-02, -6.34106770e-02,\n",
       "        -2.19259271e-03, -1.16060358e-02,  2.53959242e-02, -5.77127337e-02,\n",
       "         2.50133034e-02,  7.29051381e-02, -6.13422617e-02, -2.86903307e-02,\n",
       "         2.06024689e-03,  8.79237205e-02,  1.19339358e-02, -1.92842008e-32,\n",
       "        -1.13939233e-02, -3.50413620e-02,  4.19868790e-02,  1.17696486e-02,\n",
       "         5.23530468e-02, -3.43589000e-02,  2.73568481e-02,  2.08445359e-02,\n",
       "        -1.03410035e-02, -1.68308243e-02, -4.45846245e-02,  1.05669284e-02,\n",
       "         6.18973821e-02,  9.44936275e-02, -6.17756918e-02,  5.24566844e-02,\n",
       "         1.13191418e-01,  2.86060628e-02, -8.47160146e-02, -1.62532330e-02,\n",
       "        -1.61346719e-02,  1.01161949e-01, -4.08219993e-02, -4.21427600e-02,\n",
       "        -4.29398455e-02,  6.21785931e-02,  1.71954501e-02,  2.37833411e-02,\n",
       "        -8.59973282e-02,  3.06853801e-02, -2.81311404e-02, -8.78163874e-02,\n",
       "        -1.22775529e-02,  9.63528156e-02, -2.23200899e-02, -4.50367145e-02,\n",
       "        -1.84228476e-02, -2.56144553e-02,  4.13243771e-02,  4.85375635e-02,\n",
       "        -2.49409564e-02, -4.53940816e-02,  2.64466405e-02,  1.75824650e-02,\n",
       "         6.50975630e-02, -9.91816446e-02, -4.42860499e-02,  1.61654260e-02,\n",
       "        -4.54406142e-02, -7.05770329e-02,  4.69271913e-02,  6.32627215e-03,\n",
       "         3.21154632e-02, -6.69564605e-02,  1.12510085e-01, -1.71790319e-03,\n",
       "        -4.10111845e-02, -8.68534262e-05,  6.95137009e-02, -3.34252529e-02,\n",
       "         3.40690017e-02,  7.38593265e-02,  3.15376022e-03,  1.19064949e-01,\n",
       "        -2.26225890e-02, -1.11520989e-02, -1.54929496e-02, -3.68549898e-02,\n",
       "         2.73986235e-02, -8.25179294e-02, -2.12857258e-02,  7.30377808e-03,\n",
       "        -6.67885691e-02,  2.31057964e-02, -7.47078881e-02,  6.34249523e-02,\n",
       "        -4.12976891e-02,  1.27696157e-01, -4.27455455e-03,  2.98922993e-02,\n",
       "         2.51764082e-03, -5.64641729e-02,  5.97488042e-03,  4.75125089e-02,\n",
       "        -1.72904544e-02, -1.18521350e-02, -3.83832073e-03, -1.04047880e-01,\n",
       "         1.17749706e-01, -3.12857255e-02, -8.90422147e-03,  4.12782244e-02,\n",
       "         1.18399356e-02,  2.44954303e-02,  3.10189780e-02, -5.12779614e-08,\n",
       "        -1.94626441e-03, -6.47577122e-02, -5.81220277e-02,  3.22320499e-02,\n",
       "        -1.14133628e-02, -2.08469573e-02,  3.36900689e-02, -6.17663786e-02,\n",
       "        -5.94899654e-02,  4.93952930e-02,  3.38843018e-02, -3.02643161e-02,\n",
       "         3.24728675e-02,  2.92481910e-02,  1.13855964e-02, -1.49579439e-02,\n",
       "         2.00547930e-02,  4.27083522e-02, -3.22103128e-02, -5.64295091e-02,\n",
       "         7.32141212e-02, -9.72100496e-02,  9.48110688e-03,  5.27855679e-02,\n",
       "        -2.25006286e-02, -5.36900721e-02, -2.66243760e-02, -1.13785937e-01,\n",
       "         2.67658476e-02, -1.76870394e-02,  1.28254360e-02,  2.57339031e-02,\n",
       "         8.35480765e-02, -6.82847127e-02,  6.94068074e-02,  8.35433602e-02,\n",
       "        -3.03503592e-02,  5.24762273e-02,  3.37132660e-04,  7.99124315e-02,\n",
       "        -1.21218078e-02, -3.97064425e-02,  1.11654855e-01,  1.36508849e-02,\n",
       "         1.82447862e-02, -5.93780093e-02, -4.88811061e-02, -3.04132774e-02,\n",
       "         6.38435408e-02, -5.49845882e-02, -2.99757719e-02, -6.15019165e-02,\n",
       "         6.99507445e-02,  3.23906988e-02, -3.30509171e-02,  8.95861760e-02,\n",
       "        -3.65244225e-02,  7.89555348e-03, -3.25192325e-02,  1.28854932e-02,\n",
       "         3.46299820e-02, -3.92249003e-02, -6.87561408e-02, -2.14037225e-02],\n",
       "       dtype=float32),\n",
       " {'source': 'llama2.pdf',\n",
       "  'filename': 'llama2.pdf',\n",
       "  'end_index': 257,\n",
       "  'file_size': 252376,\n",
       "  'file_type': 'pdf',\n",
       "  'chunk_size': 512,\n",
       "  'chunk_index': 1,\n",
       "  'start_index': 167,\n",
       "  'token_count': 29,\n",
       "  'embedding_model': 'all-MiniLM-L6-v2',\n",
       "  'embedding_dimension': 384,\n",
       "  'similarity_threshold': 0.7},\n",
       " datetime.datetime(2025, 9, 24, 23, 49, 39, 208998, tzinfo=datetime.timezone(datetime.timedelta(seconds=25200))))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1f5fa406",
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_model = './embedded_model/all-MiniLM-L6-v2'\n",
    "# embedding_generator = EmbeddingGenerator(embedding_model)\n",
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('./deployment/.env')\n",
    "\n",
    "query = \"What is Llama 2?\"\n",
    "results = pipeline.search_documents(\n",
    "    query=query,\n",
    "    limit=100,\n",
    "    threshold=0.5\n",
    ")\n",
    "\n",
    "# Step 2: Build context for LLM\n",
    "context = \"\\n\\n\".join([f\"[Context {i+1}]: {r['text']}\" for i, r in enumerate(results)])\n",
    "\n",
    "# Step 3: Generate response with Gemini (if available)\n",
    "gemini_key = os.getenv('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=gemini_key)\n",
    "if gemini_key:\n",
    "    model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "    prompt = f\"\"\"Answer based on this context:\n",
    "            {context}\n",
    "            Question: {query}\n",
    "            Answer:\"\"\"\n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "    answer = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6de7646f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'chunk_id': '02bc7fc5-d0ec-4db2-8fc2-c3bcb3861baf',\n",
       "  'text': 'Llama 2 is a new technology that carries risks with use. ',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 251781,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 1364,\n",
       "   'start_index': 251724,\n",
       "   'token_count': 13,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.772544677934748},\n",
       " {'chunk_id': 'c6795880-1e64-4a4a-843d-eb1cc7dc27cc',\n",
       "  'text': 'Llama 2.\\nHardware and Software (Section 2.2)\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 250675,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 1357,\n",
       "   'start_index': 250630,\n",
       "   'token_count': 13,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.6636578443356534},\n",
       " {'chunk_id': '7bf46749-da65-4716-9221-3b9c1c366845',\n",
       "  'text': '2.Llama 2-Chat , a fine-tuned version of Llama 2 that is optimized for dialogue use cases. ',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 9054,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 78,\n",
       "   'start_index': 8963,\n",
       "   'token_count': 27,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.6438806673395269},\n",
       " {'chunk_id': '7487f65e-f275-41c3-be08-591e3902c40f',\n",
       "  'text': '. . . . . . . . . . . . . . . . . . . . . . 28\\n4.4 Safety Evaluation of Llama 2-Chat . . . . . . . . . . . . . . . . . . . . . . . . . ',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 3135,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 28,\n",
       "   'start_index': 3000,\n",
       "   'token_count': 59,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.6346311322795054},\n",
       " {'chunk_id': '413230d4-e3d2-421a-bf6a-090ba5555525',\n",
       "  'text': '. . . . . . . . 5\\n2.3 Llama 2 Pretrained Model Evaluation . ',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 2191,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 11,\n",
       "   'start_index': 2131,\n",
       "   'token_count': 21,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.6313296116983439},\n",
       " {'chunk_id': '449ce31b-2ebf-4d89-84db-1206c774b238',\n",
       "  'text': 'be incurred by other companies, saving more global resources.\\n2.3 Llama 2 Pretrained Model Evaluation\\nIn this section, we report the results for the Llama 1 andLlama 2 base models, MosaicML Pretrained\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 16992,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 123,\n",
       "   'start_index': 16791,\n",
       "   'token_count': 47,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.6268243718429277},\n",
       " {'chunk_id': '9caeca09-3167-42aa-b208-f1cc94a5282a',\n",
       "  'text': 'important proxies for the final performance of Llama 2-Chat . ',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 40357,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 247,\n",
       "   'start_index': 40295,\n",
       "   'token_count': 15,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.6219455559801087},\n",
       " {'chunk_id': '0b653d83-38b1-49e9-878c-8f74a80cdd91',\n",
       "  'text': 'English, and has notcovered, nor could it coverall scenarios. For these reasons, aswith all LLMs,\\nLlama 2’s potential outputs cannot be predicted in advance, and the model may in some instances\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 252013,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 1366,\n",
       "   'start_index': 251819,\n",
       "   'token_count': 45,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.6186217026670334},\n",
       " {'chunk_id': '089e91a1-abeb-4e74-88b2-972a1640151e',\n",
       "  'text': 'We compare the performance of Llama 2 with Llama 1 (Touvron et al., 2023), Falcon (Almazrouei et al.,\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 70403,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 413,\n",
       "   'start_index': 70301,\n",
       "   'token_count': 34,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.6149264986835107},\n",
       " {'chunk_id': '58928e6b-289a-4e4b-bdc6-ebf7554c700b',\n",
       "  'text': 'Overview Llama 2 was pretrained on 2 trillion tokens of data from publicly available\\nsources. The fine-tuning data includes publicly available instruction datasets, as\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 251313,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 1362,\n",
       "   'start_index': 251145,\n",
       "   'token_count': 34,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.6147845065079954},\n",
       " {'chunk_id': '12fe15ee-871c-48c8-8bb1-390a16050856',\n",
       "  'text': 'be applied before deployment of base Llama 2 models.\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 72448,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 420,\n",
       "   'start_index': 72395,\n",
       "   'token_count': 11,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.60105064526955},\n",
       " {'chunk_id': 'bf77c595-3354-4f6d-87b3-c3ff4294cda1',\n",
       "  'text': '§We are delaying the release of the 34B model due to a lack of time to sufficiently red team.\\n¶https://ai.meta.com/llama\\n‖https://github.com/facebookresearch/llama\\n4\\nFigure4: Trainingof Llama 2-Chat : Thisprocessbeginswiththe pretraining ofLlama 2 usingpublicly\\navailableonlinesources. Followingthis,wecreateaninitialversionof Llama 2-Chat throughtheapplication\\nofsupervised fine-tuning . ',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 10486,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 82,\n",
       "   'start_index': 10097,\n",
       "   'token_count': 122,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5929586114597863},\n",
       " {'chunk_id': '82ea81c1-db94-4e32-8f7b-47918ce0fd09',\n",
       "  'text': 'Llama 2 openly to encourage responsible AI innovation. ',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 112147,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 620,\n",
       "   'start_index': 112092,\n",
       "   'token_count': 10,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.591491156055735},\n",
       " {'chunk_id': 'daaedbed-72fd-4672-9172-9f6d5e9088d5',\n",
       "  'text': 'License A custom commercial license is available at: ai.meta.com/resources/\\nmodels-and-libraries/llama-downloads/\\nWhere to send com-\\nmentsInstructions on how to provide feedback or comments on the model can be\\nfound in the model README, or by opening an issue in the GitHub repository\\n(https://github.com/facebookresearch/llama/ ).\\nIntended Use\\nIntended Use Cases Llama 2 is intended for commercial and research use in English. ',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 250246,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 1353,\n",
       "   'start_index': 249818,\n",
       "   'token_count': 107,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5891766585182135},\n",
       " {'chunk_id': 'b2141b50-7e71-4f50-a7dd-c5dce90264b0',\n",
       "  'text': 'Processed Tokens (Billions)1.41.51.61.71.81.92.02.12.2Train PPLLlama-2\\n7B\\n13B\\n34B\\n70B\\nFigure 5: Training Loss for Llama 2 models. We compare the training loss of the Llama 2 family of models.\\nWe observe that after pretraining on 2T Tokens, the models still did not show any sign of saturation.\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 13804,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 102,\n",
       "   'start_index': 13510,\n",
       "   'token_count': 90,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5793786316184153},\n",
       " {'chunk_id': '1fd0b595-593b-4395-b7d2-927af5603cbc',\n",
       "  'text': 'We then discuss the\\nlimitations of Llama 2-Chat (Section 5.2). ',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 102465,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 575,\n",
       "   'start_index': 102402,\n",
       "   'token_count': 18,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5783953085174313},\n",
       " {'chunk_id': 'd5fa1179-6f70-47bb-964e-9d454be54ee0',\n",
       "  'text': 'Itisimportanttonotethattheseevaluationsusingautomaticmetricsareby\\nno means fully comprehensive, due to the complex nature of toxicity and bias in LLMs, but the benchmarks\\nwe selected are representative of our understanding that Llama 2-Chat improves on critical aspects of LLM\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 228799,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 1261,\n",
       "   'start_index': 228522,\n",
       "   'token_count': 63,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5774495773747501},\n",
       " {'chunk_id': '2ae784fb-ef22-4079-bf02-b81d319a109d',\n",
       "  'text': 'We release\\nvariants of this model with 7B, 13B, and 70B parameters as well.\\nWebelievethattheopenreleaseofLLMs,whendonesafely,willbeanetbenefittosociety. LikeallLLMs,\\nLlama 2 is a new technology that carries potential risks with use (Bender et al., 2021b; Weidinger et al., 2021;\\nSolaimanet al.,2023). Testingconductedtodate hasbeeninEnglish andhasnot— andcouldnot— cover\\nall scenarios. Therefore, before deploying any applications of Llama 2-Chat , developers should perform\\nsafetytestingand tuningtailoredtotheirspecificapplicationsofthemodel. Weprovidearesponsibleuse\\nguide¶and code examples‖to facilitate the safe deployment of Llama 2 andLlama 2-Chat . More details of\\nour responsible release strategy can be found in Section 5.3.\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 9789,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 79,\n",
       "   'start_index': 9054,\n",
       "   'token_count': 204,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5756512455836373},\n",
       " {'chunk_id': 'b46915d2-51eb-4dc9-96be-1b41b4a7132a',\n",
       "  'text': 'Model Dates Llama 2 was trained between January 2023 and July 2023.\\nStatus This is a static model trained on an offline dataset. Future versions of the tuned\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 249742,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 1351,\n",
       "   'start_index': 249584,\n",
       "   'token_count': 35,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5746525950833506},\n",
       " {'chunk_id': 'da956a6d-3dff-4928-bbf6-8702066a9121',\n",
       "  'text': 'of hobbies and public figures, we asked Llama 2-Chat to generate it, avoiding a mismatch between the\\ninstructionandmodelknowledge(e.g.,askingthemodeltoactassomeoneithadnotencounteredduring\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 50872,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 307,\n",
       "   'start_index': 50683,\n",
       "   'token_count': 56,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5728673341891571},\n",
       " {'chunk_id': 'd7c6267a-93f2-4426-8849-efc950666699',\n",
       "  'text': 'Ingeneral,weareobservingthat Llama 2-Chat becomessaferresponding\\nto unsafe prompts with more safety data used. For example, Llama 2-Chat learns to refuse to generate\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 187497,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 1068,\n",
       "   'start_index': 187331,\n",
       "   'token_count': 44,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5724882654097223},\n",
       " {'chunk_id': '62e41245-d08c-4f23-afb0-6e12be8ff671',\n",
       "  'text': 'Ingeneral,whencomparedtoFalconandMPT,thefine-tuned\\nLlama 2-Chat showsthebestperformanceintermsoftoxicityandtruthfulness. Afterfine-tuning, Llama\\n2-Chattends to have an increase in positive sentiment overall for many of the demographic groups in BOLD.\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 101669,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 570,\n",
       "   'start_index': 101418,\n",
       "   'token_count': 72,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5707104203089007},\n",
       " {'chunk_id': '0f84f396-550d-4762-9683-d96e85637e59',\n",
       "  'text': 'produceinaccurateorobjectionableresponsestouserprompts. Therefore,beforedeployingany\\napplications of Llama 2, developers should perform safety testing and tuning tailored to their\\nspecific applications of the model. ',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 252229,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 1367,\n",
       "   'start_index': 252013,\n",
       "   'token_count': 49,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5700185126099311},\n",
       " {'chunk_id': '055507c3-6bac-4391-a4c6-036a7daf2fac',\n",
       "  'text': 'Please see the Responsible Use Guide available available at\\nhttps://ai.meta.com/llama/responsible-user-guide\\nTable 52: Model card for Llama 2 .\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 252373,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 1368,\n",
       "   'start_index': 252229,\n",
       "   'token_count': 37,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5690011633934327},\n",
       " {'chunk_id': '6f1f192e-e24f-46e0-a48c-ad92274610be',\n",
       "  'text': '2-Chatmodels.\\nWe are releasing the following models to the general public for research and commercial use‡:\\n1.Llama 2 ,anupdatedversionof Llama 1,trainedonanewmixofpubliclyavailabledata. ',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 8681,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 75,\n",
       "   'start_index': 8494,\n",
       "   'token_count': 56,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.564609721805984},\n",
       " {'chunk_id': '304ad309-1164-44b6-a7d4-ee8d6029707a',\n",
       "  'text': 'MMLU details. In Table 19, we report details of the MMLU (Hendrycks et al., 2020) evaluation for Llama\\n2models and others open-source models.\\nStandard Benchmarks. In Table 20, we show results on several standard benchmarks.\\nCodeGeneration. InTable21,wecompareresultsof Llama 2 withpopularopensourcemodelsonthe\\nHuman-Eval and MBPP code generation benchmarks.\\nWorld Knowledge. We evaluate the Llama 2 model together with other open-source models on the Natu-\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 164635,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 955,\n",
       "   'start_index': 164178,\n",
       "   'token_count': 120,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5624646563157089},\n",
       " {'chunk_id': 'bf1cccb9-4b84-4201-ab8c-6eb0fcca1304',\n",
       "  'text': 'The primary architectural differences from Llama 1 include increased context length\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 12400,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 93,\n",
       "   'start_index': 12316,\n",
       "   'token_count': 12,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5554628537733275},\n",
       " {'chunk_id': '8f99e4b2-c7b6-46b7-8215-177e4482a392',\n",
       "  'text': 'safety concerns. We encourage more community research and red teaming in this area.\\n5.2 Limitations and Ethical Considerations\\nLlama 2-Chat is subject to the same well-recognized limitations of other LLMs, including a cessation of\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 109471,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 608,\n",
       "   'start_index': 109240,\n",
       "   'token_count': 47,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5512428405863868},\n",
       " {'chunk_id': '9c4c53f2-79ec-470d-8ac8-a8085becec42',\n",
       "  'text': 'MPT, and the 7B Llama 1. This percentage increases for pretrained Llama 1 andLlama 2 with a\\nlarger size. After instruction fine-tuning, both 7B and 13B Llama 2-Chat improved about 20% in\\ntruthfulness,30B Llama 2-Chat improvedabout24%,and70B Llama 2-Chat improvedabout14%\\ncompared to their pretrained versions.\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 225845,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 1246,\n",
       "   'start_index': 225535,\n",
       "   'token_count': 89,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5448459602662864},\n",
       " {'chunk_id': 'e8d39dea-cc0e-4193-b070-49472ab80ebb',\n",
       "  'text': 'diminish any capabilities they might have offered for those use cases.\\nWhile we attempted to reasonably balance safety with helpfulness, in some instances, our safety tuning goes\\ntoo far. Users of Llama 2-Chat may observe an overly cautious approach, with the model erring on the side\\nof declining certain requests or responding with too many safety details.\\nUsersofthepretrainedmodelsneedtobeparticularlycautious,andshouldtakeextrastepsintuningand\\ndeployment as described in our Responsible Use Guide.§§\\n5.3 Responsible Release Strategy\\nReleaseDetails. Wemake Llama 2 availableforbothresearchandcommercialuseat https://ai.meta.\\ncom/resources/models-and-libraries/llama/ . Thosewhouse Llama 2 mustcomplywiththetermsof\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 111513,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 616,\n",
       "   'start_index': 110795,\n",
       "   'token_count': 177,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5411390711234902},\n",
       " {'chunk_id': '044f9ce9-7dfa-41ee-bd7d-59129e8aa63d',\n",
       "  'text': 'onthedatasets,toallow Llama 2 tobemorewidelyusableacrosstasks(e.g.,itcanbebetterusedforhate\\nspeechclassification),whileavoidingthepotentialfortheaccidentaldemographicerasuresometimescaused\\nbyover-scrubbing. Importantly,thisallows Llama 2-Chat togeneralizemoreeffectivelyduringsafetytuning\\nwith fewer examples (Welbl et al., 2021; Korbak et al., 2023; Xu et al., 2021). As a result, Llama 2 models\\nshould be used carefully and deployed only after significant safety tuning is applied.\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 63509,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 379,\n",
       "   'start_index': 63025,\n",
       "   'token_count': 146,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5408105625171475},\n",
       " {'chunk_id': '74d3fefc-b3c9-4c2a-9e04-d6cebb9bfe42',\n",
       "  'text': '. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 77\\n2\\nFigure 1: Helpfulness human evaluation results for Llama\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 4391,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 47,\n",
       "   'start_index': 4261,\n",
       "   'token_count': 47,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5282208166056743},\n",
       " {'chunk_id': 'aadf3ee7-3c0e-4777-b703-72528fda453d',\n",
       "  'text': 'The fine-tuned Llama 2-Chat shows more positivity in\\nsentimentscoresthanthepretrainedversionsdo. ChatGPTtendstohavemoreneutralsentiment\\nscoresinitsmodelgenerations. ',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 227038,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 1253,\n",
       "   'start_index': 226873,\n",
       "   'token_count': 50,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5211228778655247},\n",
       " {'chunk_id': '28cff39b-d3d1-42a8-aaba-ad57d420901c',\n",
       "  'text': 'of1.0. Figure 5 (a) shows the training loss for Llama 2 with these hyperparameters.\\n5\\nTraining Data Params Context\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 12945,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 98,\n",
       "   'start_index': 12830,\n",
       "   'token_count': 31,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5201879215912621},\n",
       " {'chunk_id': '16e6aa8e-56c3-4dbb-b559-3c6c14c5f3be',\n",
       "  'text': 'Therefore, for a fair comparison, we additionally compute the final results\\nusingGPT-4toassesswhichgenerationispreferred. TheorderinwhichChatGPTand Llama 2-Chat outputs\\nappearedinGPT-4promptarerandomlyswappedtoavoidanybias. Asexpected,thewin-rateinfavorof\\nLlama 2-Chat is less pronounced, although obtaining more than a 60% win-rate for our latest Llama 2-Chat .\\nThe prompts correspond to a validation set of 1,586and584prompts for safety and helpfulness, respectively.\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 57566,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 352,\n",
       "   'start_index': 57096,\n",
       "   'token_count': 136,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5200012457369831},\n",
       " {'chunk_id': 'c9076ba4-fbf8-4759-8659-b914228eac5a',\n",
       "  'text': 'Helpfulness\\nJudge: GPT -4HarmlessnessFigure 11: Evolution of Llama 2-Chat . We show the evolution after multiple iterations fine-tuning for the\\nwin-rate%of Llama 2-Chat comparedtoChatGPT. Left: thejudgeisourrewardmodel,whichmayfavor\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 56163,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 344,\n",
       "   'start_index': 55930,\n",
       "   'token_count': 71,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5191985832928365},\n",
       " {'chunk_id': '6af44bb1-2c1d-4720-87a5-b4affbb04dee',\n",
       "  'text': 'As shown in Table 3, Llama 2 models outperform Llama 1 models. In particular, Llama 2 70B improves the\\nresultsonMMLUandBBHby ≈5and≈8points,respectively,comparedto Llama 1 65B.Llama 2 7Band30B\\nmodelsoutperformMPTmodelsofthecorrespondingsizeonallcategoriesbesidescodebenchmarks. Forthe\\nFalcon models, Llama 2 7B and 34B outperform Falcon 7B and 40B models on all categories of benchmarks.\\nAdditionally, Llama 2 70B model outperforms all open-source models.\\nIn addition to open-source models, we also compare Llama 2 70B results to closed-source models. As shown\\nin Table 4, Llama 2 70B is close to GPT-3.5 (OpenAI, 2023) on MMLU and GSM8K, but there is a significant\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 20282,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 139,\n",
       "   'start_index': 19617,\n",
       "   'token_count': 199,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5163663818626852},\n",
       " {'chunk_id': '0201e031-24a2-4bb4-8b7a-01eed9dd94c7',\n",
       "  'text': 'for our larger models. Table 1 compares the attributes of the new Llama 2 models with the Llama 1 models.\\n2.1 Pretraining Data\\nOur training corpus includes a new mix of data from publicly available sources, which does not include data\\nfromMeta’sproductsorservices. ',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 11516,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 87,\n",
       "   'start_index': 11251,\n",
       "   'token_count': 63,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5160430804452711},\n",
       " {'chunk_id': 'a23e5ed1-8a3e-4524-b0c6-a0af320bc4ae',\n",
       "  'text': 'well Llama 2-Chat responses fulfill users’ requests and provide requested information; safety refers to\\nwhether Llama 2-Chat ’s responses are unsafe, e.g., “giving detailed instructions on making a bomb” could\\nbe considered helpful but is unsafe according to our safety guidelines. Separating the two allows us to\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 27180,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 174,\n",
       "   'start_index': 26866,\n",
       "   'token_count': 64,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.514017108444479},\n",
       " {'chunk_id': '9c54a566-6201-443c-9dcf-d2d80c7d8635',\n",
       "  'text': 'this study, the role of reward signals is to learn human preference for Llama 2-Chat outputs rather than\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 33830,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 205,\n",
       "   'start_index': 33725,\n",
       "   'token_count': 22,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5135439191324743},\n",
       " {'chunk_id': '177a7c23-c83f-452a-a7e0-8770d376294d',\n",
       "  'text': 'theresultsinSection5,Figure20). Llama 2-Chat improvementalsoshiftedthemodel’sdatadistribution.\\nSince reward model accuracy can quickly degrade if not exposed to this new sample distribution, i.e., from\\nhyper-specialization(Scialometal.,2020b),itisimportantbeforeanew Llama 2-Chat tuningiterationto\\ngather new preference data using the latest Llama 2-Chat iterations. This step helps keep the reward model\\non-distribution and maintain an accurate reward for the latest model.\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 28700,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 176,\n",
       "   'start_index': 28225,\n",
       "   'token_count': 120,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5112036327603747},\n",
       " {'chunk_id': 'b14a50e1-feff-4143-b62b-87537d6a518c',\n",
       "  'text': '“Whatisyourname?”),tomeasurethemulti-turnmemoryabilityof Llama 2-Chat . ',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 176880,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 1013,\n",
       "   'start_index': 176808,\n",
       "   'token_count': 30,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5094090255918865},\n",
       " {'chunk_id': 'f1aa9f24-2a5a-4aee-81f1-5aa630658c75',\n",
       "  'text': 'knowledge updates post-pretraining, potential for non-factual generation such as unqualified advice, and a\\npropensity towards hallucinations.\\nFurthermore,ourinitialversionof Llama 2-Chat predominantlyconcentratedonEnglish-languagedata.\\nWhile our experimental observations suggestthe model has garnered some proficiency in other languages,\\nitsproficiencyislimited,dueprimarilytothelimitedamountofpretrainingdataavailableinnon-English\\nlanguages(asdocumentedinTable10). Consequently,themodel’sperformanceinlanguagesotherthan\\nEnglish remains fragile and should be used with caution.\\nLike other LLMs, Llama 2 may generate harmful, offensive, or biased content due to its training on publicly\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 110158,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 609,\n",
       "   'start_index': 109471,\n",
       "   'token_count': 162,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5068096971639741},\n",
       " {'chunk_id': '4812d92d-de35-4b43-a402-9903f367aac4',\n",
       "  'text': 'In Figure 8, we report for a Llama 2-Chat -SFT (left) and a Llama 2-Chat -RLHF (right), the maximum\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 45426,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 277,\n",
       "   'start_index': 45326,\n",
       "   'token_count': 37,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5035486071244407},\n",
       " {'chunk_id': '21e058f1-4131-4186-8042-ad7cf98e4c06',\n",
       "  'text': 'generation. Leveragingsuchresponsescoresasrewards,wecanoptimize Llama 2-Chat duringRLHFfor\\nbetter human preference alignment and improved helpfulness and safety.\\nOthers have found that helpfulness and safety sometimes trade off (Bai et al., 2022a), which can make it\\n',\n",
       "  'metadata': {'source': 'llama2.pdf',\n",
       "   'filename': 'llama2.pdf',\n",
       "   'end_index': 30094,\n",
       "   'file_size': 252376,\n",
       "   'file_type': 'pdf',\n",
       "   'chunk_size': 512,\n",
       "   'chunk_index': 183,\n",
       "   'start_index': 29827,\n",
       "   'token_count': 66,\n",
       "   'embedding_model': 'all-MiniLM-L6-v2',\n",
       "   'embedding_dimension': 384,\n",
       "   'similarity_threshold': 0.7},\n",
       "  'document_id': '62fea6ed-85a6-464f-b0fd-5ec2402d0dd8',\n",
       "  'similarity': 0.5016094302446819}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3652862",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
