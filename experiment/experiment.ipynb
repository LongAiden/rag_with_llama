{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09ed2de3",
   "metadata": {},
   "source": [
    "Project Structure\n",
    "- Setup Chunking and processing steps for inputs (PDFs, docx, txt)\n",
    "- Setup PGVector Store (VS) + postgresql => Done\n",
    "- Using LLMs (OpenAI, Gemini,...) to query vectors from VS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d89cd4e",
   "metadata": {},
   "source": [
    "# Create PostgreDB "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "356d472c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv('/Users/longnguyen/Documents/coding/fastapi/rag_with_llama/deployment/.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2fc01b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "db_name = os.environ['POSTGRES_DB']\n",
    "host = \"localhost\"\n",
    "password = os.environ['POSTGRES_PASSWORD']\n",
    "port = \"5432\"\n",
    "user = os.environ['POSTGRES_USER']\n",
    "# conn = psycopg2.connect(connection_string)\n",
    "conn = psycopg2.connect(\n",
    "    dbname=db_name,\n",
    "    host=host,\n",
    "    password=password,\n",
    "    port=port,\n",
    "    user=user,\n",
    ")\n",
    "conn.autocommit = True\n",
    "\n",
    "# with conn.cursor() as c:\n",
    "#     c.execute(f\"DROP DATABASE IF EXISTS {db_name}\")\n",
    "#     c.execute(f\"CREATE DATABASE {db_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c0431d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'user': 'admin', 'channel_binding': 'prefer', 'dbname': 'rag_db', 'host': 'localhost', 'port': '5432', 'options': '', 'sslmode': 'prefer', 'sslcompression': '0', 'sslcertmode': 'allow', 'sslsni': '1', 'ssl_min_protocol_version': 'TLSv1.2', 'gssencmode': 'prefer', 'krbsrvname': 'postgres', 'gssdelegation': '0', 'target_session_attrs': 'any', 'load_balance_hosts': 'disable'}\n",
      "Connection is active\n"
     ]
    }
   ],
   "source": [
    "print(conn.status)\n",
    "print(conn.get_dsn_parameters())\n",
    "with conn.cursor() as cursor:\n",
    "    cursor.execute(\"SELECT 1\")\n",
    "    print(\"Connection is active\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeb5fee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d6fbefe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0f75f42d",
   "metadata": {},
   "source": [
    "# Checking file input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "08ca7925",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field, field_validator\n",
    "from pydantic_ai import Agent, RunContext\n",
    "from uuid import UUID\n",
    "from chonkie import TokenChunker, SemanticChunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1770fbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/project/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "\n",
    "from pathlib import Path\n",
    "import PyPDF2\n",
    "from chonkie import SemanticChunker\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract text from PDF file using PyPDF2.\n",
    "\n",
    "    Args:\n",
    "        pdf_path (str): Path to the PDF file\n",
    "\n",
    "    Returns:\n",
    "        str: Extracted text from all pages\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        pdf_reader = PyPDF2.PdfReader(file)\n",
    "\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text() + \"\\n\"\n",
    "\n",
    "    return text\n",
    "\n",
    "\n",
    "def chunk_with_semantic_chunker(text, chunk_size=512, similarity_threshold=0.7, embedding_model=None):\n",
    "    \"\"\"\n",
    "    Chunk text using Chonkie's SemanticChunker with custom embedding model.\n",
    "\n",
    "    Args:\n",
    "        text (str): Text to chunk\n",
    "        chunk_size (int): Maximum tokens per chunk\n",
    "        similarity_threshold (float): Similarity threshold for semantic chunking\n",
    "        embedding_model: Custom embedding model (SentenceTransformer or similar)\n",
    "\n",
    "    Returns:\n",
    "        list: List of chunks\n",
    "    \"\"\"\n",
    "    if embedding_model:\n",
    "        chunker = SemanticChunker(\n",
    "            chunk_size=chunk_size,\n",
    "            similarity_threshold=similarity_threshold,\n",
    "            embedding_model=embedding_model\n",
    "        )\n",
    "    else:\n",
    "        # Use default embedding model\n",
    "        chunker = SemanticChunker(\n",
    "            chunk_size=chunk_size,\n",
    "            similarity_threshold=similarity_threshold\n",
    "        )\n",
    "\n",
    "    chunks = chunker.chunk(text)\n",
    "    return chunks\n",
    "\n",
    "\n",
    "def save_chunks_to_file(chunks, output_path, chunker_type):\n",
    "    \"\"\"\n",
    "    Save chunks to a text file.\n",
    "\n",
    "    Args:\n",
    "        chunks (list): List of chunks\n",
    "        output_path (str): Output file path\n",
    "        chunker_type (str): Type of chunker used\n",
    "    \"\"\"\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(f\"Chunks created using {chunker_type}\\n\")\n",
    "        f.write(\"=\" * 50 + \"\\n\\n\")\n",
    "\n",
    "        for i, chunk in enumerate(chunks, 1):\n",
    "            f.write(f\"Chunk {i}:\\n\")\n",
    "            f.write(\"-\" * 20 + \"\\n\")\n",
    "            f.write(f\"{chunk.text}\\n\\n\")\n",
    "            f.write(f\"Tokens: {chunk.token_count}\\n\")\n",
    "            if hasattr(chunk, 'start_index'):\n",
    "                f.write(f\"Start Index: {chunk.start_index}\\n\")\n",
    "            if hasattr(chunk, 'end_index'):\n",
    "                f.write(f\"End Index: {chunk.end_index}\\n\")\n",
    "            f.write(\"\\n\" + \"=\"*50 + \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5aedf171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 1: Loading documents\n",
      "\n",
      "Step 2: Chunking with SemanticChunker\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/Caskroom/miniconda/base/envs/project/lib/python3.12/site-packages/chonkie/embeddings/auto.py:87: UserWarning: Failed to load minishlab/potion-base-32M with Model2VecEmbeddings: model2vec is not available. Please install it via `pip install chonkie[model2vec]`\n",
      "Falling back to loading default provider model.\n",
      "  warnings.warn(\n",
      "/usr/local/Caskroom/miniconda/base/envs/project/lib/python3.12/site-packages/chonkie/embeddings/auto.py:95: UserWarning: Failed to load the default model for Model2VecEmbeddings: model2vec is not available. Please install it via `pip install chonkie[model2vec]`\n",
      "Falling back to SentenceTransformerEmbeddings.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStep 1: Loading documents\")\n",
    "# texts = extract_text_from_pdf(r'D:\\Project\\rag_with_llama\\docs\\llama2.pdf')\n",
    "texts = extract_text_from_pdf(r'../docs/llama2.pdf')\n",
    "\n",
    "# Create output directory\n",
    "output_dir = \"chunked_output\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "print(\"\\nStep 2: Chunking with SemanticChunker\")\n",
    "semantic_chunks = chunk_with_semantic_chunker(\n",
    "    texts,\n",
    "    chunk_size=512,\n",
    "    similarity_threshold=0.7\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5eb4060f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chunk(text='Llama 2 : Open Foundation and Fine-Tuned Chat Models\n",
       "Hugo Touvron∗Louis Martin†Kevin Stone†\n",
       "Peter Albert Amjad Almahairi Yasmine Babaei Nikolay Bashlykov Soumya Batra\n",
       "', token_count=43, start_index=0, end_index=167)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "semantic_chunks[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5448515",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "class EmbeddingGenerator:\n",
    "    \"\"\"Generate embeddings using SentenceTransformers.\"\"\"\n",
    "\n",
    "    def __init__(self, model_name: str = 'all-MiniLM-L6-v2'):\n",
    "        \"\"\"\n",
    "        Initialize embedding generator.\n",
    "\n",
    "        Args:\n",
    "            model_name: SentenceTransformer model name\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.embedding_dim = self.model.get_sentence_embedding_dimension()\n",
    "\n",
    "    def embed_text(self, text: str) -> List[float]:\n",
    "        \"\"\"\n",
    "        Generate embedding for a single text.\n",
    "        Args:\n",
    "            text: Input text\n",
    "        Returns:\n",
    "            List of embedding values\n",
    "        \"\"\"\n",
    "        embedding = self.model.encode(text)\n",
    "        return embedding.tolist()\n",
    "\n",
    "    def embed_batch(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"\n",
    "        Generate embeddings for multiple texts.\n",
    "        Args:\n",
    "            texts: List of input texts\n",
    "        Returns:\n",
    "            List of embedding lists\n",
    "        \"\"\"\n",
    "        embeddings = self.model.encode(texts)\n",
    "        return [emb.tolist() for emb in embeddings]\n",
    "\n",
    "embedding_model = './embedded_model/all-MiniLM-L6-v2'\n",
    "embedding_generator = EmbeddingGenerator(embedding_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "132653c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_txt = embedding_generator.embed_batch(semantic_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33e004a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1332"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embedded_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e38b2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from pgvector.psycopg2 import register_vector  # Missing import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dde964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -- First, turn off the pager to avoid the 'more' error\n",
    "# \\pset pager off\n",
    "\n",
    "# -- Now run your queries (notice the semicolon at the end)\n",
    "# SELECT version();\n",
    "\n",
    "# SELECT 2+2 AS result;\n",
    "\n",
    "# SELECT NOW();\n",
    "\n",
    "# SELECT 'Hello PostgreSQL!' AS message;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f89015a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sentence_transformers\n",
    "# model = sentence_transformers.SentenceTransformer('all-MiniLM-L6-v2')\n",
    "# model.save('./embedded_model/all-MiniLM-L6-v2')\n",
    "# model_test = sentence_transformers.SentenceTransformer('./embedded_model/all-MiniLM-L6-v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb580acd",
   "metadata": {},
   "source": [
    "# Test fulll flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2fa63fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddc6f726",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "from pathlib import Path\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "from fastapi import FastAPI, File, UploadFile, HTTPException, Form\n",
    "from fastapi.responses import HTMLResponse\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "import sys\n",
    "sys.path.append('../document_processing')  # Go up one level, then into folder\n",
    "\n",
    "import sys\n",
    "sys.path.append('../docs')  # Go up one level, then into folder\n",
    "\n",
    "# Your existing components - unchanged\n",
    "from embed_chunks_to_db_v2 import ChunkEmbeddingPipeline, EmbeddingGenerator, VectorStore\n",
    "import google.generativeai as genai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8266c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "db_params = {\n",
    "    'host': os.getenv('DB_HOST', 'localhost'),\n",
    "    'port': os.getenv('DB_PORT', '5432'),\n",
    "    'dbname': os.getenv('DB_NAME', 'rag_db'),\n",
    "    'user': os.getenv('DB_USER', 'admin'),\n",
    "    'password': os.getenv('DB_PASSWORD', 'admin')\n",
    "}\n",
    "\n",
    "table_name = 'document_chunks'\n",
    "\n",
    "# Don't initialize models at startup\n",
    "pipeline = None\n",
    "def get_pipeline():\n",
    "    global pipeline\n",
    "    if pipeline is None:\n",
    "        pipeline = ChunkEmbeddingPipeline(\n",
    "                    db_params=db_params,\n",
    "                    embedding_model='./embedded_model/all-MiniLM-L6-v2',  # Your embedding model path\n",
    "                    table_name='document_chunks'  # Your existing table name\n",
    "                )\n",
    "    return pipeline\n",
    "\n",
    "pipeline = get_pipeline()\n",
    "file = pipeline.extract_text_from_pdf(r'../docs/llama2.pdf')\n",
    "chunks = pipeline.chunk_text(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62b751d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Vector type working: [1. 2. 3.]\n",
      "✓ Cosine distance: 1.000\n",
      "✓ Embedding column: ('embedding', 'USER-DEFINED')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_pgvector_connection():\n",
    "    \"\"\"Validate pgvector integration at the connection level\"\"\"\n",
    "    vector_store = VectorStore(db_params, 'document_chunks')\n",
    "    \n",
    "    try:\n",
    "        conn = vector_store._get_connection()\n",
    "        with conn.cursor() as cur:\n",
    "            # Test 1: Confirm pgvector types are registered\n",
    "            cur.execute(\"SELECT '[1,2,3]'::vector;\")\n",
    "            result = cur.fetchone()[0]\n",
    "            print(f\"✓ Vector type working: {result}\")\n",
    "            \n",
    "            # Test 2: Verify cosine distance operator\n",
    "            cur.execute(\"SELECT '[1,0,0]'::vector <=> '[0,1,0]'::vector;\")\n",
    "            distance = cur.fetchone()[0]\n",
    "            print(f\"✓ Cosine distance: {distance:.3f}\")\n",
    "            \n",
    "            # Test 3: Table schema validation\n",
    "            cur.execute(f\"\"\"\n",
    "                SELECT column_name, data_type \n",
    "                FROM information_schema.columns \n",
    "                WHERE table_name = '{vector_store.table_name}' \n",
    "                AND column_name = 'embedding'\n",
    "            \"\"\")\n",
    "            schema = cur.fetchone()\n",
    "            print(f\"✓ Embedding column: {schema}\")\n",
    "            \n",
    "        conn.close()\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ pgvector connection failed: {e}\")\n",
    "        return False\n",
    "    \n",
    "test_pgvector_connection()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8291d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Chunk:\n",
    "    \"\"\"Chunk data structure to match your existing interface.\"\"\"\n",
    "    id: str\n",
    "    document_id: str\n",
    "    text: str\n",
    "    embedding: List[float]\n",
    "    metadata: Optional[Dict] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "232fc845",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    }
   ],
   "source": [
    "# Generate embeddings in batch\n",
    "print(\"Generating embeddings...\")\n",
    "embeddings = pipeline.embedding_generator.embed_batch([chunk.text for chunk in chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac37546d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_size = 512\n",
    "similarity_threshold = 0.7\n",
    "filename = 'llama2.pdf'\n",
    "file_type = 'pdf'\n",
    "file_size = len(file)\n",
    "document_id = str(uuid.uuid4())\n",
    "metadata = {'source': 'llama2.pdf'}\n",
    "\n",
    "# Create Chunk objects using your interface\n",
    "chunk_objects = []\n",
    "for i, (chunk, embedding) in enumerate(zip(chunks, embeddings)):\n",
    "    chunk_metadata = {\n",
    "        'chunk_index': i,\n",
    "        'token_count': chunk.token_count,\n",
    "        'start_index': getattr(chunk, 'start_index', None),\n",
    "        'end_index': getattr(chunk, 'end_index', None),\n",
    "        'chunk_size': chunk_size,\n",
    "        'similarity_threshold': similarity_threshold,\n",
    "        'embedding_model': pipeline.embedding_generator.model_name,\n",
    "        'embedding_dimension': len(embedding),\n",
    "        'filename': filename,\n",
    "        'file_type': file_type,\n",
    "        'file_size': file_size\n",
    "    }\n",
    "\n",
    "    # Add any additional metadata\n",
    "    if metadata:\n",
    "        chunk_metadata.update(metadata)\n",
    "\n",
    "    chunk_obj = Chunk(\n",
    "        id=str(uuid.uuid4()),\n",
    "        document_id=document_id,\n",
    "        text=chunk.text,\n",
    "        embedding=embedding,\n",
    "        metadata=chunk_metadata\n",
    "    )\n",
    "    chunk_objects.append(chunk_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31b78593",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting chunks into database using pgvector...\n"
     ]
    }
   ],
   "source": [
    "# Use your add_chunks method with pgvector\n",
    "print(\"Inserting chunks into database using pgvector...\")\n",
    "pipeline.vector_store.add_chunks(chunk_objects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ee851e77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Search operational: 1 results\n"
     ]
    }
   ],
   "source": [
    "test_results = pipeline.search_documents('text', limit=1, threshold=0.1)\n",
    "assert len(test_results) > 0, \"Insert succeeded but search failed\"\n",
    "print(f\"✓ Search operational: {len(test_results)} results\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cdb0aae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Data truncated instantly\n",
      "✓ Table schema dropped\n"
     ]
    }
   ],
   "source": [
    "def fast_reset_vector_store(vector_store):\n",
    "    \"\"\"Two-step reset: TRUNCATE then DROP for optimal performance\"\"\"\n",
    "    conn = vector_store._get_connection()\n",
    "    \n",
    "    try:\n",
    "        with conn.cursor() as cur:\n",
    "            # Step 1: Instant data removal (no WAL overhead)\n",
    "            cur.execute(f\"TRUNCATE TABLE {vector_store.table_name} CASCADE;\")\n",
    "            print(\"✓ Data truncated instantly\")\n",
    "            \n",
    "            # Step 2: Clean schema removal\n",
    "            cur.execute(f\"DROP TABLE {vector_store.table_name} CASCADE;\")\n",
    "            print(\"✓ Table schema dropped\")\n",
    "            \n",
    "        conn.commit()\n",
    "        \n",
    "    except Exception as e:\n",
    "        conn.rollback()\n",
    "        raise e\n",
    "    finally:\n",
    "        conn.close()\n",
    "\n",
    "# Usage\n",
    "fast_reset_vector_store(pipeline.vector_store)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9569d22d",
   "metadata": {},
   "source": [
    "# Check inserting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8653e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify success\n",
    "conn = pipeline.vector_store._get_connection()\n",
    "with conn.cursor() as cur:\n",
    "    cur.execute(f\"SELECT COUNT(*) FROM {pipeline.vector_store.table_name}\")\n",
    "    count_after = cur.fetchone()[0]\n",
    "    \n",
    "    # Validate embedding integrity\n",
    "    cur.execute(f\"\"\"\n",
    "        SELECT *\n",
    "        FROM {pipeline.vector_store.table_name} \n",
    "        ORDER BY created_at DESC LIMIT 2\n",
    "    \"\"\")\n",
    "    \n",
    "    results = cur.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b800dad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('8b22d921-57b9-4668-a91e-6b6d456975c5',\n",
       " 'e5cf45cb-c5b6-486a-8bf8-62b08dae5f86',\n",
       " 'Prajjwal Bhargava Shruti Bhosale Dan Bikel Lukas Blecher Cristian Canton Ferrer Moya Chen\\n',\n",
       " array([ 7.12140696e-03,  1.58904791e-01, -4.11183350e-02, -1.60896853e-02,\n",
       "        -1.19244307e-01,  1.66793168e-02,  7.66921416e-02,  2.09899573e-03,\n",
       "        -7.99256749e-03, -3.11005227e-02,  6.69132546e-03, -1.19025588e-01,\n",
       "         9.55456719e-02, -4.00688946e-02,  2.43876386e-03,  2.39557661e-02,\n",
       "        -2.64740479e-03,  2.02800948e-02,  7.83016626e-03, -7.15690479e-02,\n",
       "        -2.38059536e-02, -1.06638953e-01, -9.48437303e-03,  2.73222160e-02,\n",
       "        -6.30895719e-02, -4.59780265e-03,  1.97287090e-02,  1.22995349e-03,\n",
       "         2.02850197e-02, -3.98318842e-02, -3.29108760e-02,  1.30037338e-01,\n",
       "         7.59432688e-02, -2.78772302e-02, -1.24752801e-02,  8.16548020e-02,\n",
       "        -5.94116375e-02,  4.51856200e-03,  1.69892237e-02, -4.73481510e-03,\n",
       "        -2.29553003e-02,  7.49921007e-03, -2.45867595e-02, -6.85824230e-02,\n",
       "         4.61077094e-02, -7.90486112e-03,  3.45357247e-02,  4.29701358e-02,\n",
       "        -1.81527771e-02,  3.94391920e-03, -1.12031236e-01, -1.33850090e-02,\n",
       "         2.95563228e-02, -5.68636581e-02, -1.91135630e-02, -4.89593707e-02,\n",
       "        -2.09068134e-02,  2.54858341e-02,  2.22643763e-02, -7.60168433e-02,\n",
       "         6.34240359e-02,  4.02081162e-02, -7.23926648e-02, -2.93466821e-03,\n",
       "        -6.95488788e-03, -1.99586563e-02, -5.47327138e-02, -6.26659095e-02,\n",
       "        -5.50054051e-02, -3.49979997e-02,  5.01937792e-02, -4.63739112e-02,\n",
       "        -5.19338585e-02, -2.70535182e-02, -4.35601696e-02, -4.47140448e-02,\n",
       "         1.51811773e-02, -2.63849515e-02, -5.31596877e-02, -5.92831075e-02,\n",
       "        -8.20158124e-02, -3.04792449e-02,  2.42745113e-02,  5.42198680e-02,\n",
       "        -2.90953908e-02,  4.95423526e-02, -7.87439849e-03, -3.05383652e-02,\n",
       "        -2.47602817e-02, -3.60754617e-02,  9.20124631e-03,  4.02520597e-02,\n",
       "        -2.28689667e-02,  4.39353622e-02, -7.07207546e-02,  3.69134471e-02,\n",
       "         2.79467599e-03,  2.21683010e-02,  1.65243093e-02,  9.99062806e-02,\n",
       "         2.19089929e-02,  2.90145352e-02,  6.05171621e-02,  1.35711310e-02,\n",
       "        -1.58481196e-01, -4.70414758e-02,  4.13059033e-02,  6.38688952e-02,\n",
       "         1.91920493e-02,  1.73744205e-02, -3.81577276e-02,  7.30550243e-03,\n",
       "        -3.25665250e-02, -1.01912536e-01, -4.59164269e-02, -1.08444644e-02,\n",
       "        -2.01329812e-02,  4.14438508e-02, -3.18212919e-02,  2.55877953e-02,\n",
       "         3.90040018e-02,  5.42499870e-02, -6.37430251e-02, -6.79228753e-02,\n",
       "         1.62571426e-02, -2.59845573e-02,  5.26356809e-02,  1.99033895e-32,\n",
       "        -4.95870896e-02, -7.90224820e-02,  9.21913385e-02,  3.56467515e-02,\n",
       "         4.26651584e-03, -5.04415296e-02,  5.72547875e-03, -8.60541016e-02,\n",
       "        -2.67258752e-02, -3.08261719e-02,  4.47884761e-02, -3.62987593e-02,\n",
       "         1.18824020e-02, -5.44895083e-02,  1.08716592e-01,  4.03876416e-02,\n",
       "        -2.28538122e-02, -9.44421887e-02, -1.51067581e-02, -4.98380221e-04,\n",
       "         3.80847827e-02,  5.21641783e-02,  4.60770987e-02,  1.45992497e-02,\n",
       "         3.70202735e-02,  5.84117472e-02,  1.20251246e-01, -1.98231265e-02,\n",
       "         6.56109722e-03,  5.06151877e-02,  8.78756419e-02, -2.27500610e-02,\n",
       "        -8.11563060e-02, -4.98249643e-02, -2.63267178e-02, -2.03694217e-03,\n",
       "        -5.87148927e-02, -1.28698712e-02, -5.34305833e-02, -4.73356470e-02,\n",
       "         2.73009297e-02, -7.30978325e-02,  2.87800916e-02, -3.14410403e-02,\n",
       "         2.24582739e-02,  4.58434671e-02,  7.48047233e-02,  6.37950450e-02,\n",
       "         1.31526240e-03,  2.74903197e-02, -2.85093207e-02,  4.53276411e-02,\n",
       "         5.38060116e-03,  4.09435444e-02,  1.66452155e-02, -6.75904304e-02,\n",
       "         2.06154585e-02,  2.42883805e-02, -7.47049004e-02,  8.88601542e-02,\n",
       "         2.31793579e-02,  7.47747868e-02, -3.27695310e-02,  9.43940729e-02,\n",
       "        -3.37526724e-02, -5.39264530e-02,  6.41730335e-03, -6.64854944e-02,\n",
       "         4.43784036e-02, -6.38131574e-02, -4.49762978e-02, -2.10196376e-02,\n",
       "         3.02143563e-02,  7.05433786e-02, -8.37857649e-02, -3.68053734e-04,\n",
       "        -6.19670115e-02, -5.90805821e-02, -7.67596066e-02,  4.91671115e-02,\n",
       "        -5.38995564e-02,  1.21843601e-02,  2.39255130e-02, -6.34107068e-02,\n",
       "        -2.19259877e-03, -1.16061233e-02,  2.53959503e-02, -5.77127114e-02,\n",
       "         2.50133630e-02,  7.29051307e-02, -6.13422655e-02, -2.86903568e-02,\n",
       "         2.06026551e-03,  8.79236907e-02,  1.19338864e-02, -1.92842038e-32,\n",
       "        -1.13938963e-02, -3.50413248e-02,  4.19868939e-02,  1.17696496e-02,\n",
       "         5.23530394e-02, -3.43588740e-02,  2.73569506e-02,  2.08444968e-02,\n",
       "        -1.03409700e-02, -1.68308839e-02, -4.45846170e-02,  1.05669694e-02,\n",
       "         6.18974492e-02,  9.44936052e-02, -6.17756061e-02,  5.24566360e-02,\n",
       "         1.13191389e-01,  2.86060069e-02, -8.47159848e-02, -1.62532646e-02,\n",
       "        -1.61345769e-02,  1.01161927e-01, -4.08220477e-02, -4.21427302e-02,\n",
       "        -4.29398231e-02,  6.21786155e-02,  1.71953198e-02,  2.37833466e-02,\n",
       "        -8.59973133e-02,  3.06854192e-02, -2.81312242e-02, -8.78163353e-02,\n",
       "        -1.22774942e-02,  9.63528752e-02, -2.23201513e-02, -4.50365692e-02,\n",
       "        -1.84228402e-02, -2.56144125e-02,  4.13243696e-02,  4.85374965e-02,\n",
       "        -2.49409042e-02, -4.53941002e-02,  2.64466479e-02,  1.75825302e-02,\n",
       "         6.50975853e-02, -9.91816446e-02, -4.42860462e-02,  1.61653794e-02,\n",
       "        -4.54406291e-02, -7.05770031e-02,  4.69271392e-02,  6.32629916e-03,\n",
       "         3.21155638e-02, -6.69565126e-02,  1.12510130e-01, -1.71790586e-03,\n",
       "        -4.10111696e-02, -8.68386778e-05,  6.95135891e-02, -3.34252678e-02,\n",
       "         3.40690352e-02,  7.38593936e-02,  3.15383612e-03,  1.19064987e-01,\n",
       "        -2.26225611e-02, -1.11520886e-02, -1.54929906e-02, -3.68549041e-02,\n",
       "         2.73986198e-02, -8.25178847e-02, -2.12857574e-02,  7.30377901e-03,\n",
       "        -6.67885989e-02,  2.31057908e-02, -7.47078359e-02,  6.34249896e-02,\n",
       "        -4.12977077e-02,  1.27696186e-01, -4.27457923e-03,  2.98922658e-02,\n",
       "         2.51769414e-03, -5.64642176e-02,  5.97492093e-03,  4.75124680e-02,\n",
       "        -1.72904711e-02, -1.18521005e-02, -3.83834960e-03, -1.04047894e-01,\n",
       "         1.17749691e-01, -3.12857516e-02, -8.90419073e-03,  4.12782393e-02,\n",
       "         1.18399234e-02,  2.44954843e-02,  3.10189929e-02, -5.12779650e-08,\n",
       "        -1.94628153e-03, -6.47576526e-02, -5.81220277e-02,  3.22321281e-02,\n",
       "        -1.14133516e-02, -2.08470095e-02,  3.36900726e-02, -6.17663488e-02,\n",
       "        -5.94900027e-02,  4.93952930e-02,  3.38843912e-02, -3.02643012e-02,\n",
       "         3.24727930e-02,  2.92482506e-02,  1.13855880e-02, -1.49579477e-02,\n",
       "         2.00547241e-02,  4.27083448e-02, -3.22102942e-02, -5.64295240e-02,\n",
       "         7.32140392e-02, -9.72099826e-02,  9.48114786e-03,  5.27855344e-02,\n",
       "        -2.25005746e-02, -5.36900647e-02, -2.66243778e-02, -1.13785952e-01,\n",
       "         2.67658345e-02, -1.76870245e-02,  1.28254388e-02,  2.57338714e-02,\n",
       "         8.35479945e-02, -6.82846680e-02,  6.94067553e-02,  8.35433826e-02,\n",
       "        -3.03503927e-02,  5.24762757e-02,  3.37074016e-04,  7.99124017e-02,\n",
       "        -1.21217621e-02, -3.97063643e-02,  1.11654788e-01,  1.36508513e-02,\n",
       "         1.82448793e-02, -5.93780242e-02, -4.88810763e-02, -3.04133724e-02,\n",
       "         6.38435930e-02, -5.49845956e-02, -2.99757738e-02, -6.15019202e-02,\n",
       "         6.99507222e-02,  3.23906988e-02, -3.30508985e-02,  8.95862803e-02,\n",
       "        -3.65244411e-02,  7.89547246e-03, -3.25191990e-02,  1.28854765e-02,\n",
       "         3.46299522e-02, -3.92249227e-02, -6.87561184e-02, -2.14037150e-02],\n",
       "       dtype=float32),\n",
       " {'source': 'llama2.pdf',\n",
       "  'filename': 'llama2.pdf',\n",
       "  'end_index': 257,\n",
       "  'file_size': 252376,\n",
       "  'file_type': 'pdf',\n",
       "  'chunk_size': 512,\n",
       "  'chunk_index': 1,\n",
       "  'start_index': 167,\n",
       "  'token_count': 29,\n",
       "  'embedding_model': './embedded_model/all-MiniLM-L6-v2',\n",
       "  'embedding_dimension': 384,\n",
       "  'similarity_threshold': 0.7},\n",
       " datetime.datetime(2025, 9, 24, 18, 2, 9, 750290, tzinfo=datetime.timezone(datetime.timedelta(seconds=25200))))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1f5fa406",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1758712330.021180  127741 alts_credentials.cc:93] ALTS creds ignored. Not running on GCP and untrusted ALTS is not enabled.\n"
     ]
    }
   ],
   "source": [
    "# embedding_model = './embedded_model/all-MiniLM-L6-v2'\n",
    "# embedding_generator = EmbeddingGenerator(embedding_model)\n",
    "\n",
    "query = \"What is Llama 2?\"\n",
    "results = pipeline.search_documents(\n",
    "    query=query,\n",
    "    limit=100,\n",
    "    threshold=0.5\n",
    ")\n",
    "\n",
    "# Step 2: Build context for LLM\n",
    "context = \"\\n\\n\".join([f\"[Context {i+1}]: {r['text']}\" for i, r in enumerate(results)])\n",
    "\n",
    "# Step 3: Generate response with Gemini (if available)\n",
    "gemini_key = os.getenv('GOOGLE_API_KEY')\n",
    "genai.configure(api_key=gemini_key)\n",
    "if gemini_key:\n",
    "    model = genai.GenerativeModel('gemini-2.5-flash')\n",
    "    prompt = f\"\"\"Answer based on this context:\n",
    "            {context}\n",
    "            Question: {query}\n",
    "            Answer:\"\"\"\n",
    "    \n",
    "    response = model.generate_content(prompt)\n",
    "    answer = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6de7646f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Llama 2 is an updated version of Llama 1, trained on a new mix of publicly available data. It is a new technology and an LLM (Large Language Model) that was pretrained on 2 trillion tokens of data from publicly available sources. Llama 2 is a static model trained on an offline dataset between January 2023 and July 2023.\\n\\nLlama 2 is released openly to encourage responsible AI innovation and is intended for commercial and research use in English. Variants of the Llama 2 model are available with 7B, 13B, and 70B parameters. It carries potential risks with use, and before deployment, developers should perform safety testing and tuning.'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
